{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aggregate-external",
   "metadata": {},
   "source": [
    "# Tarea 2\n",
    "\n",
    "La meta de esta tarea es mejorar el 0,48 de accuracy que obtuvo el árbol de decisión entrenado para el dataset de helados, con un train/test split de 75-25. Partamos por cargar el dataset y el split. \n",
    "\n",
    "### Detalles administrativos\n",
    "\n",
    "La tarea es individual. Para la entrega, sube este notebook al cuestionario del siding, el plazo para hacerlo es el **Viernes 24 de Septiembre, a las 20:00 hrs**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "extensive-wilson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>female</th>\n",
       "      <th>ice_cream</th>\n",
       "      <th>video</th>\n",
       "      <th>puzzle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   id  female  ice_cream  video  puzzle\n",
       "0           0   70       0          0     47      57\n",
       "1           1  121       1          1     63      61\n",
       "2           2   86       0          0     58      31\n",
       "3           3  141       0          0     53      56\n",
       "4           4  172       0          1     53      61"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "helados = pd.read_csv('Ice_cream.csv')\n",
    "helados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "marked-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(helados[[\"female\",\"puzzle\",\"video\"]], helados[\"ice_cream\"], test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-costs",
   "metadata": {},
   "source": [
    "## Parte I: boosting simple\n",
    "\n",
    "Lo primero que vas a hacer es un modelo de boosting simple. Implementa una clase que tenga metodos _fit_ y _predict_.\n",
    "\n",
    "El método fit recibe un set X, y para entrenar, donde X es un dataframe e y es una serie de números 0 o 1, y hace lo siguiente: \n",
    "- primero entrena un árbol de decisión A1(por ejemplo, usando sklearn como vimos en clases) con X e y\n",
    "- Sea C el conjunto de tuplas en X para los cuales A1 clasificó mal (es decir, el resultado de A1 para esa tupla es distinto de lo que tiene y), y sea y_c el pedazo de y correspondiente a esas tuplas. \n",
    "- ahora entrena un árbol de decisión A2, pero usando solo C, y_c. \n",
    "\n",
    "El método predict recibe un set X (del mismo número de dimensiones que el que se uso para fit), y ejecuta lo siguiente: \n",
    "- usa _predict_proba_ o un método similar para conseguir las probabilidades según el árbol A1 de que cada tupla en X sea clasificada como **1**\n",
    "- usa _predict_proba_ o un método similar para conseguir las probabilidades según el árbol A2 de que cada tupla en X sea clasificada como **1**\n",
    "- sea p la probabilidad calculada como 0,7 veces la proabilidad según A1 y 0,3 veces la probabilidad según A2. Tu clase predice clase 1 si p es **mayor** que 0.5, y si no predice un 0. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "cleared-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "### escribe tu clase aquí\n",
    "from sklearn import tree\n",
    "\n",
    "class Boosting:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.A1 = tree.DecisionTreeClassifier()\n",
    "        self.A2 = tree.DecisionTreeClassifier()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.A1.fit(X, y)\n",
    "        pred = self.A1.predict(X)\n",
    "        \n",
    "        \n",
    "        C = pd.DataFrame(columns=[\"female\", \"puzzle\", \"video\"])\n",
    "        \n",
    "        y_c_dict = {}\n",
    "        \n",
    "        for i in range(0, len(pred)):\n",
    "            if pred[i] != y.iloc[i]:\n",
    "                C = C.append(X.iloc[[i]])\n",
    "                y_c_key = y.iloc[[i]].index[0]\n",
    "                y_c_value = y.iloc[i]\n",
    "                y_c_dict[y_c_key] = y_c_value\n",
    "        \n",
    "        y_c = pd.Series(y_c_dict)\n",
    "        \n",
    "        self.A2.fit(C, y_c)\n",
    "        \n",
    "        return(self.A1, self.A2)\n",
    "        \n",
    "    def predict(self, X, y):\n",
    "        pred_A1 = self.A1.predict(X)\n",
    "        pred_proba_A1 = self.A1.predict_proba(X)\n",
    "        pred_A2 = self.A2.predict(X)\n",
    "        pred_proba_A2 = self.A2.predict_proba(X)\n",
    "        \n",
    "        new_results = []\n",
    "        \n",
    "        for i in range(0,len(pred_A1)):\n",
    "            \n",
    "            new_pred_proba = (pred_proba_A1[i] * 0.7 + pred_proba_A2[i] * 0.3)\n",
    "            \n",
    "            if new_pred_proba[0] <= 0.5:\n",
    "                new_results.append(1)\n",
    "            else:\n",
    "                new_results.append(0)\n",
    "                \n",
    "        return new_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-principal",
   "metadata": {},
   "source": [
    "Lo segundo: Usa ahora el set de datos de test para ver el accuracy score de tu clase cuando se entrena con los datos de train de los helados pero se testea con el set de test. ¿Cómo se compara con la del árbol 1? ¿Con la del árbol 2? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "applicable-burner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1: 0.48\n",
      "Accuracy 2: 0.5\n",
      "Accuracy 3: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X1 = Boosting()\n",
    "A1 = X1.fit(X_train, y_train)[0]\n",
    "A2 = X1.fit(X_train, y_train)[1]\n",
    "\n",
    "new_results = X1.predict(X_test, y_test)\n",
    "\n",
    "pred1 = A1.predict(X_test)\n",
    "acc1= accuracy_score(y_test, pred1)\n",
    "\n",
    "pred2 = A2.predict(X_test)\n",
    "acc2 = accuracy_score(y_test, pred2)\n",
    "\n",
    "acc3 = accuracy_score(y_test, new_results)\n",
    "\n",
    "\n",
    "print(f\"Accuracy 1: {acc1}\")\n",
    "print(f\"Accuracy 2: {acc2}\")\n",
    "print(f\"Accuracy 3: {acc3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-korean",
   "metadata": {},
   "source": [
    "\n",
    "## Parte 2: agregando árboles\n",
    "\n",
    "Modifica acá abajo tu clase para que agregue un tercér árbol, que se entrene sobre el subconjunto de tuplas de C que el árbol 2 no logra clasificar bien, o bien (si este subconjunto es vacío), sobre el conjunto C' de tuplas de X que el clasificador de la parte I no logra clasificar bien. \n",
    "\n",
    "Busca si hay algún valor de pesos que puedes entregarles a los árboles en el método _predict_ para que tu nuevo clasificador mejore su accuracy score con el set de test (con pesos nos referimos a la ponderación que se le da a la probabilidad de cada árbol - para la clase con dos árboles los pesos fueron 0.7 y 0.3). Puedes limitar tu búsqueda a valores de alfa con un decimal: 0, 0.1, 0.2, hasta 0.9, 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "precise-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "### escribe la clase modificada aquí\n",
    "\n",
    "class Boosting2:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.A1 = tree.DecisionTreeClassifier()\n",
    "        self.A2 = tree.DecisionTreeClassifier()\n",
    "        self.A3 = tree.DecisionTreeClassifier()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.A1.fit(X, y)\n",
    "        pred = self.A1.predict(X)\n",
    "        \n",
    "        \n",
    "        C = pd.DataFrame(columns=[\"female\", \"puzzle\", \"video\"])\n",
    "        \n",
    "        y_c_dict = {}\n",
    "        \n",
    "        for i in range(0, len(pred)):\n",
    "            if pred[i] != y.iloc[i]:\n",
    "                C = C.append(X.iloc[[i]])\n",
    "                y_c_key = y.iloc[[i]].index[0]\n",
    "                y_c_value = y.iloc[i]\n",
    "                y_c_dict[y_c_key] = y_c_value\n",
    "        \n",
    "        y_c = pd.Series(y_c_dict)\n",
    "\n",
    "        self.A2.fit(C, y_c)\n",
    "        \n",
    "        pred2 = self.A2.predict(X)\n",
    "        \n",
    "        \n",
    "        C2 = pd.DataFrame(columns=[\"female\", \"puzzle\", \"video\"])\n",
    "        \n",
    "        y_c2_dict = {}\n",
    "        \n",
    "        empty_detector = 0\n",
    "        \n",
    "        for i in range(0, len(pred2)):\n",
    "            if pred2[i] != y.iloc[i]:\n",
    "                empty_detector += 1\n",
    "                C2 = C2.append(X.iloc[[i]])\n",
    "                y_c2_key = y.iloc[[i]].index[0]\n",
    "                y_c2_value = y.iloc[i]\n",
    "                y_c2_dict[y_c2_key] = y_c2_value\n",
    "                \n",
    "        if empty_detector == 0:\n",
    "            classifier = tree.DecisionTreeClassifier()\n",
    "            classifier.fit(X,y)\n",
    "            \n",
    "            pred3 = classifier.predict(X)\n",
    "            \n",
    "            for i in range(0, len(pred3)):\n",
    "                if pred3[i] != y.iloc[i]:\n",
    "                    C2 = C2.append(X.iloc[[i]])\n",
    "                    y_c2_key = y.iloc[[i]].index[0]\n",
    "                    y_c2_value = y.iloc[i]\n",
    "                    y_c2_dict[y_c2_key] = y_c2_value\n",
    "                    \n",
    "            y_c2 = pd.Series(y_c2_dict)\n",
    "            self.A3.fit(C2, y_c2)\n",
    "            \n",
    "        else:\n",
    "            y_c2 = pd.Series(y_c2_dict)\n",
    "            self.A3.fit(C2, y_c2)\n",
    "        \n",
    "        return(self.A1, self.A2, self.A3)\n",
    "        \n",
    "    def predict(self, X, y, accuracy_1, accuracy_2, accuracy_3):\n",
    "        pred_A1 = self.A1.predict(X)\n",
    "        pred_proba_A1 = self.A1.predict_proba(X)\n",
    "        pred_A2 = self.A2.predict(X)\n",
    "        pred_proba_A2 = self.A2.predict_proba(X)\n",
    "        pred_A3 = self.A3.predict(X)\n",
    "        pred_proba_A3 = self.A3.predict_proba(X)\n",
    "        \n",
    "        new_results = []\n",
    "        \n",
    "        for i in range(0,len(pred_A1)):\n",
    "            \n",
    "            new_pred_proba = (pred_proba_A1[i] * accuracy_1 + pred_proba_A2[i] * accuracy_2 + pred_proba_A3[i] * accuracy_3)\n",
    "            \n",
    "            if new_pred_proba[0] <= 0.5:\n",
    "                new_results.append(1)\n",
    "            else:\n",
    "                new_results.append(0)\n",
    "                \n",
    "        return new_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "undefined-curve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "Accuracy: 0.48\n",
      "Accuracy: 0.52\n",
      "Accuracy: 0.52\n",
      "Accuracy: 0.48\n",
      "Accuracy: 0.56\n",
      "Accuracy: 0.52\n",
      "Accuracy: 0.4\n",
      "\n",
      "A partir de los resultados podemos notar que por medio de variaciones de nuestro alpha, el valor del accuracy no logra superar el resultado de la parte 1 con 0,56.\n",
      "Sin embargo podemos notar que aplicando Boosting, en promedio nuestro accuracy siempre se vera incrementado.\n"
     ]
    }
   ],
   "source": [
    "### busca el alfa o reporta el alfa encontrado acá. \n",
    "\n",
    "X2 = Boosting2()\n",
    "X2.fit(X_train, y_train)\n",
    "\n",
    "new_results = X2.predict(X_test, y_test, 0.5, 0.2, 0.3)\n",
    "acc = accuracy_score(y_test, new_results)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "new_results = X2.predict(X_test, y_test, 0.4, 0.2, 0.4)\n",
    "acc = accuracy_score(y_test, new_results)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "new_results = X2.predict(X_test, y_test, 0.6, 0.3, 0.1)\n",
    "acc = accuracy_score(y_test, new_results)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "new_results = X2.predict(X_test, y_test, 0.5, 0.4, 0.1)\n",
    "acc = accuracy_score(y_test, new_results)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "new_results = X2.predict(X_test, y_test, 0.8, 0.2, 0)\n",
    "acc = accuracy_score(y_test, new_results)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "new_results = X2.predict(X_test, y_test, 0.5, 0.5, 0)\n",
    "acc = accuracy_score(y_test, new_results)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "new_results = X2.predict(X_test, y_test, 0.4, 0.4, 0.2)\n",
    "acc = accuracy_score(y_test, new_results)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "new_results = X2.predict(X_test, y_test, 0.2, 0.3, 0.5)\n",
    "acc = accuracy_score(y_test, new_results)\n",
    "print(f\"Accuracy: {acc}\")\n",
    "\n",
    "print(\"\\nA partir de los resultados podemos notar que por medio de variaciones de nuestro alpha, el valor del accuracy no logra superar el resultado de la parte 1 con 0,56.\\nSin embargo podemos notar que aplicando Boosting, en promedio nuestro accuracy siempre se vera incrementado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
