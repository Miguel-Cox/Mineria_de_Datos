{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "horizontal-highway",
   "metadata": {},
   "source": [
    "# Actividad 1: Regresion\n",
    "\n",
    "Esta actividad debe ser completada antes del Viernes de esta semana, a las 20:00 horas. Deberás subir el notebook completo y reportar tu nivel de avance en el cuestionario habilitado para el siding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-divide",
   "metadata": {},
   "source": [
    "La meta, por supuesto, es aprender a estimar un modelo de regresión lineal. Comenzemos por cargar datos para armar una regresion. Esta vez nuestros datos son tabulares, pero pandas los puede leer sin mucho problema (están limpios). Los datos corresponden al dataset usado por Francis Galton para estudiar la estatura de las personas (de este ejercicio, publicado en 1886, viene el término 'regresión'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "affected-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 898 entries, 0 to 897\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   family  898 non-null    object \n",
      " 1   father  898 non-null    float64\n",
      " 2   mother  898 non-null    float64\n",
      " 3   gender  898 non-null    object \n",
      " 4   height  898 non-null    float64\n",
      " 5   kids    898 non-null    int64  \n",
      " 6   male    898 non-null    float64\n",
      " 7   female  898 non-null    float64\n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 56.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "galton = pd.read_table('galton-stata11.tab')\n",
    "galton.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-second",
   "metadata": {},
   "source": [
    "'family' es un identificador asignado a cada familia. 'father' y 'mother' es la estatura de su padre y madre. 'height' es la estatura del hijo (una vez adulto). 'gender', 'male' y 'female' son autoexplicativos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "champion-leisure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>father</th>\n",
       "      <th>mother</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>kids</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>M</td>\n",
       "      <td>73.2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>F</td>\n",
       "      <td>69.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>F</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>67.0</td>\n",
       "      <td>F</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>75.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>M</td>\n",
       "      <td>73.5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>136A</td>\n",
       "      <td>68.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>M</td>\n",
       "      <td>68.5</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>136A</td>\n",
       "      <td>68.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>M</td>\n",
       "      <td>67.7</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>136A</td>\n",
       "      <td>68.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>F</td>\n",
       "      <td>64.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>136A</td>\n",
       "      <td>68.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>F</td>\n",
       "      <td>63.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>136A</td>\n",
       "      <td>68.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>F</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    family  father  mother gender  height  kids  male  female\n",
       "0        1    78.5    67.0      M    73.2     4   1.0     0.0\n",
       "1        1    78.5    67.0      F    69.2     4   0.0     1.0\n",
       "2        1    78.5    67.0      F    69.0     4   0.0     1.0\n",
       "3        1    78.5    67.0      F    69.0     4   0.0     1.0\n",
       "4        2    75.5    66.5      M    73.5     4   1.0     0.0\n",
       "..     ...     ...     ...    ...     ...   ...   ...     ...\n",
       "893   136A    68.5    65.0      M    68.5     8   1.0     0.0\n",
       "894   136A    68.5    65.0      M    67.7     8   1.0     0.0\n",
       "895   136A    68.5    65.0      F    64.0     8   0.0     1.0\n",
       "896   136A    68.5    65.0      F    63.5     8   0.0     1.0\n",
       "897   136A    68.5    65.0      F    63.0     8   0.0     1.0\n",
       "\n",
       "[898 rows x 8 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-lithuania",
   "metadata": {},
   "source": [
    "Las alturas están en pulgadas, lo que es horrible. Las pasamos a metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "confidential-healing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>family</th>\n",
       "      <th>father</th>\n",
       "      <th>mother</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>kids</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.9939</td>\n",
       "      <td>1.7018</td>\n",
       "      <td>M</td>\n",
       "      <td>1.85928</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.9939</td>\n",
       "      <td>1.7018</td>\n",
       "      <td>F</td>\n",
       "      <td>1.75768</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.9939</td>\n",
       "      <td>1.7018</td>\n",
       "      <td>F</td>\n",
       "      <td>1.75260</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.9939</td>\n",
       "      <td>1.7018</td>\n",
       "      <td>F</td>\n",
       "      <td>1.75260</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.9177</td>\n",
       "      <td>1.6891</td>\n",
       "      <td>M</td>\n",
       "      <td>1.86690</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>136A</td>\n",
       "      <td>1.7399</td>\n",
       "      <td>1.6510</td>\n",
       "      <td>M</td>\n",
       "      <td>1.73990</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>136A</td>\n",
       "      <td>1.7399</td>\n",
       "      <td>1.6510</td>\n",
       "      <td>M</td>\n",
       "      <td>1.71958</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>136A</td>\n",
       "      <td>1.7399</td>\n",
       "      <td>1.6510</td>\n",
       "      <td>F</td>\n",
       "      <td>1.62560</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>136A</td>\n",
       "      <td>1.7399</td>\n",
       "      <td>1.6510</td>\n",
       "      <td>F</td>\n",
       "      <td>1.61290</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>136A</td>\n",
       "      <td>1.7399</td>\n",
       "      <td>1.6510</td>\n",
       "      <td>F</td>\n",
       "      <td>1.60020</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>898 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    family  father  mother gender   height  kids  male  female\n",
       "0        1  1.9939  1.7018      M  1.85928     4   1.0     0.0\n",
       "1        1  1.9939  1.7018      F  1.75768     4   0.0     1.0\n",
       "2        1  1.9939  1.7018      F  1.75260     4   0.0     1.0\n",
       "3        1  1.9939  1.7018      F  1.75260     4   0.0     1.0\n",
       "4        2  1.9177  1.6891      M  1.86690     4   1.0     0.0\n",
       "..     ...     ...     ...    ...      ...   ...   ...     ...\n",
       "893   136A  1.7399  1.6510      M  1.73990     8   1.0     0.0\n",
       "894   136A  1.7399  1.6510      M  1.71958     8   1.0     0.0\n",
       "895   136A  1.7399  1.6510      F  1.62560     8   0.0     1.0\n",
       "896   136A  1.7399  1.6510      F  1.61290     8   0.0     1.0\n",
       "897   136A  1.7399  1.6510      F  1.60020     8   0.0     1.0\n",
       "\n",
       "[898 rows x 8 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galton['father'] = 0.0254 * galton['father']\n",
    "galton['mother'] = 0.0254 * galton['mother']\n",
    "galton['height'] = 0.0254 * galton['height']\n",
    "galton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-guest",
   "metadata": {},
   "source": [
    "### Ajustando una regresión\n",
    "\n",
    "Nota que tenemos que sacar la variable 'family' y la de 'gender', por que no son números. La de gender la tenemos con male/female, y el id de familia no debería aportarnos mucho acá, así que lo sacamos sin cuidado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "exposed-rough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes: \n",
      " [ 0.39830528  0.32095528 -0.00111299  0.06616632 -0.06616632]\n",
      "Beta0: \n",
      " 0.477334232240503\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Crea un objeto regresión\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Lo entrenamos usando el dataset de Galton, queremos predecir la altura (height)\n",
    "regr.fit(galton[['father','mother','kids','male','female']], galton['height'])\n",
    "\n",
    "# Imprimimos los coeficientes (los beta). Están en el orden en que están los atributos\n",
    "print('Coeficientes: \\n', regr.coef_)\n",
    "print('Beta0: \\n', regr.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-adoption",
   "metadata": {},
   "source": [
    "Y bueno, ya tenemos una regresión. ¿Qué podemos hacer? podemos, por ejemplo, predecir cuando mediría una niña dada la altura de su papá, de su mamá y cuantos hijos tuvieron sus padres.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "remarkable-orchestra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   father  mother  kids  male  female\n",
      "0       2       2     2     1       0\n",
      "1       2       2     2     0       1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.97979571, 1.84746306])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Diccionario con dos filas, papá y mamá miden dos metros, tienen dos hijos, uno es hombre y otro mujer\n",
    "para_predecir = pd.DataFrame({'father':[2,2],'mother':[2,2],'kids':[2,2],'male':[1,0],'female':[0,1]})\n",
    "print(para_predecir)\n",
    "\n",
    "#ahora le pedimos al modelo de regresión que nos prediga la estatura de los hijos: \n",
    "regr.predict(para_predecir)\n",
    "\n",
    "#el resultado: hijo hombre mediría 1.97, hija mujer 1.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-jacob",
   "metadata": {},
   "source": [
    "Ahora bien. Hay un campo que está un poco extraño, y es la cantidad de hijos que tiene esta familia. Por qué debería influir la cantidad de hermanos en la altura de una persona? ¿Qué pasa si en vez de predecir el valor de arriba para dos hijos, predecirmos como si la familia tuviera 7 hijos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "endangered-photography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   father  mother  kids  male  female\n",
      "0       2       2     7     1       0\n",
      "1       2       2     7     0       1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.97423077, 1.84189813])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_predecir = pd.DataFrame({'father':[2,2],'mother':[2,2],'kids':[7,7],'male':[1,0],'female':[0,1]})\n",
    "print(para_predecir)\n",
    "\n",
    "\n",
    "regr.predict(para_predecir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-finger",
   "metadata": {},
   "source": [
    "El resultado cambia! Esto no hace ningún sentido: ¿cómo va a ser que la altura de las personas dependa de la cantidad de sus hermanos? Algo extraño debe estar pasando. \n",
    "\n",
    "### Ejercicio 1\n",
    "\n",
    "Entrena una regresión que solo tome en cuenta 'father', 'mother', 'male', 'female', y luego una que solo tome en cuenta 'mother', 'male', 'female'. Predice valores como los de arriba, y discute sobre cuál es mejor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "nominated-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   father  mother  male  female\n",
      "0       2       2     1       0\n",
      "1       2       2     0       1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.97744239, 1.84470323])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Lo entrenamos usando el dataset de Galton, queremos predecir la altura (height)\n",
    "regr.fit(galton[['father','mother','male','female']], galton['height'])\n",
    "para_predecir = pd.DataFrame({'father':[2,2],'mother':[2,2],'male':[1,0],'female':[0,1]})\n",
    "print(para_predecir)\n",
    "\n",
    "\n",
    "regr.predict(para_predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "grand-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mother  male  female\n",
      "0       2     1       0\n",
      "1       2     0       1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.89111328, 1.75927734])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.fit(galton[['mother','male','female']], galton['height'])\n",
    "\n",
    "para_predecir = pd.DataFrame({'mother':[2,2],'male':[1,0],'female':[0,1]})\n",
    "print(para_predecir)\n",
    "\n",
    "\n",
    "regr.predict(para_predecir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-kuwait",
   "metadata": {},
   "source": [
    "Diria que el primer caso es mejor, ya que considera la altura del padre y la estatura del hijo o \n",
    "hija se acerca más a la de sus padres correpondientes. El valor debe estar cerca de los 2 metros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-senate",
   "metadata": {},
   "source": [
    "# Seleccionando mejores modelos\n",
    "\n",
    "Antes de entender qué pasa que nuestro modelo toma en cuenta la cantidad de hermanos a la hora de predecir, veamos algo más general: ¿cómo seleccionar los mejores modelos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-triangle",
   "metadata": {},
   "source": [
    "## Alternativa 1: Mean-squared error (MSE), r^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-aspect",
   "metadata": {},
   "source": [
    "Recordemos que otra forma de ajustar una regresión es encontrar una función que minimiza los cuadrados de los errores: \n",
    "en nuestro caso el error de cada punto se calcula como el valor de height en el dataset menos el valor predicho por la regresión, todo eso al cuadrado:  Si tomamos la media de ese error, llegamos al MSE. Lógicamente, mientras mas chico el MSE, más se ajusta la función a los datos. \n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{1 \\leq i \\leq n} (y_i - \\beta^T\\bar x^i)^2$$\n",
    "\n",
    "El coeficiente r^2 corresponde a la suma de los errores, dividido por la diferencia entre cada punto y su media. \n",
    "\n",
    "$$r^2 = 1 - \\frac{\\sum_{1 \\leq i \\leq n} (y_i - \\beta^T\\bar x^i)^2}{\\sum_{1 \\leq i \\leq n} (y_i - \\bar y)^2},$$\n",
    "\n",
    "donde $$\\bar y = \\frac{\\sum_{1 \\leq i \\leq n} y_i}{n}$$\n",
    "\n",
    "El coeficiente r^2 va desde 1 (cuando la suma de los errores es cero, un modelo que se ajusta perfecto) a 0 (cuando la suma de los errores es igual a la diferencia entre cada punto y su media, el modelo no sirve para nada). \n",
    "\n",
    "Veamos como obtener el MSE, y el coeficiente r^2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bacterial-shooting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.002972\n",
      "Coeficiente r2: 0.64\n"
     ]
    }
   ],
   "source": [
    "#pedimos la predicción de todos los datos. \n",
    "galton_pred = regr.predict(galton[['father','mother','kids','male','female']])\n",
    "\n",
    "#calculamos el MSE\n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton['height'], galton_pred))\n",
    "\n",
    "#calculamos el r^2\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "compound-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.002981\n",
      "Coeficiente r2: 0.64\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(galton[['father','mother','male','female']], galton['height'])\n",
    "#pedimos la predicción de todos los datos menos kids. \n",
    "galton_pred = regr.predict(galton[['father','mother','male','female']])\n",
    "\n",
    "#calculamos el MSE\n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton['height'], galton_pred))\n",
    "\n",
    "#calculamos el r^2\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "imported-lloyd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.003625\n",
      "Coeficiente r2: 0.56\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(galton[['mother','male','female']], galton['height'])\n",
    "#pedimos la predicción de todos los datos menos kids. \n",
    "galton_pred = regr.predict(galton[['mother','male','female']])\n",
    "\n",
    "#calculamos el MSE\n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton['height'], galton_pred))\n",
    "\n",
    "#calculamos el r^2\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-malaysia",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "¿Cuál de los tres modelos que has entrenado tiene mejor MSE? ¿mejor r^2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "El modelo que tendra mejor MSE correspondera al que este más cerca del cero, en este caso corresponde al\n",
    "caso donde considera los hijos.\n",
    "Por estimación y analisis de la formula, la mejor estimación debiese de ser el caso donde se considere al\n",
    "padre y la madre, ignorando el numero de hijos. Sin embargo, puede existir el caso donde el numero de\n",
    "hijos mejore el valor del MSE ya que se consideran más datos dentro de la formula.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flexible-clerk",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-mauritius",
   "metadata": {},
   "source": [
    "Si hiciste el **Ejercicio 2**, te estarás preguntando por qué es mejor el modelo que usa la variable 'kids', siendo que no debería tener nada que ver en este caso. \n",
    "\n",
    "La respuesta a este tipo de preguntas muchas veces viene del hecho que los modelos de machine learning terminan aprendiendo *demasiado* los datos, hasta un punto en que se aprovechan de patrones espureos para poder ajustar un poquitito mejor la recta. En este caso, bien puede haber pasado algo así. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-passage",
   "metadata": {},
   "source": [
    "¿Cuál es el problema del overfitting? Que cuando queramos usar nuestro predictor en un ambiente real, los datos quizá no van a respetar esa correlación, y nuestro modelo va a terminar siendo, en la práctica, peor. Una forma bien estándar de asegurarnos que esto no pasa es dividir el set de datos, de forma de calcular el MSE con datos que son distintos a los que se usaron para entrenar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-justice",
   "metadata": {},
   "source": [
    "### Alternativa 2:  Train-test split\n",
    "\n",
    "La idea es simple: vamos a ajustar la regresión con menos datos de los que teníamos (digamos un 80% de los datos), y vamos a *reservar* los otros para calcular el MSE y el r^2 con datos realistas, que no se usaron para entrenar al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dying-carpet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family    718\n",
      "father    718\n",
      "mother    718\n",
      "gender    718\n",
      "height    718\n",
      "kids      718\n",
      "male      718\n",
      "female    718\n",
      "dtype: int64\n",
      "family    180\n",
      "father    180\n",
      "mother    180\n",
      "gender    180\n",
      "height    180\n",
      "kids      180\n",
      "male      180\n",
      "female    180\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "galton_train, galton_test = train_test_split(galton, train_size=0.80)\n",
    "print(galton_train.count())\n",
    "print(galton_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-blogger",
   "metadata": {},
   "source": [
    "Ahora usamos nuestro split: Entrenamos con el set de test **galton_test**, y cuando vayamos a ver que tan bueno es el modelo (según MSE, r^2), lo vamos a hacer usando el test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "revised-northwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.002996\n",
      "Coeficiente r2: 0.64\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Solo usamos el set de test\n",
    "regr.fit(galton_train[['father','mother','kids','male','female']], galton_train['height'])\n",
    "\n",
    "#ahora usamos el modelo regr pa predecir la altura según el set de test\n",
    "galton_pred = regr.predict(galton_test[['father','mother','kids','male','female']])\n",
    "\n",
    "#y calculamos \n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton_test['height'], galton_pred))\n",
    "\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton_test['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-popularity",
   "metadata": {},
   "source": [
    "Comparemos con el modelo sin el numero de hermanos. Vemos que el MSE ahora es ligeramente inferior, por lo que nos convendría más este modelo. ¿Cómo se compara esto con la situación anterior, cuando no hacíamos **train/test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "renewable-tactics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.002992\n",
      "Coeficiente r2: 0.64\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Solo usamos el set de test\n",
    "regr.fit(galton_train[['father','mother','male','female']], galton_train['height'])\n",
    "\n",
    "#ahora usamos el modelo regr pa predecir la altura según el set de test\n",
    "galton_pred = regr.predict(galton_test[['father','mother','male','female']])\n",
    "\n",
    "#y calculamos \n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton_test['height'], galton_pred))\n",
    "\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton_test['height'], galton_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-retail",
   "metadata": {},
   "source": [
    "### K-fold cross validation\n",
    "\n",
    "A veces tenemos mala suerte y el pedazo de test justo se lleva algunos datos muy importantes para la regresión. Para evitar esto, una mejor práctica es hacer variso splits distintos. Esto se conoce como k-fold cross validation, en donde k es el número de grupos. \n",
    "\n",
    "La práctica de k-fold cross validation consiste en: \n",
    "- particionar los datos en k grupos distintos, todos iguales\n",
    "- entrenar k modelos distintos: el modelo j-ésimo usa para entrenar todos los grupos **menos** el grupo j, y usa el grupo j para testear. \n",
    "- los indicadores de cada modelo se agregan en un número. En nuestro caso, vamos a computar el MSE y el r^2, y el total va a ser simplemente el promedio de los k. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-invite",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Implementa 5-fold cross validation. Prueba con los tres modelos que vimos, y calcula el MSE y el r^2 total para cada uno de ellos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "worthy-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error model 1: 0.002993\n",
      "Coeficiente r2 model 1: 0.64\n",
      "Mean squared error model 2: 0.003034\n",
      "Coeficiente r2 model 2: 0.63\n",
      "Mean squared error model 3: 0.003652\n",
      "Coeficiente r2 model 3: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model \n",
    "from sklearn.model_selection import KFold\n",
    "X = galton[['father','mother','kids','male','female']]\n",
    "Y = galton['height']\n",
    "KF = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "trains = []\n",
    "tests = []\n",
    "for train_index, test_index in KF.split(X):\n",
    "    trains.append(train_index)\n",
    "    tests.append(test_index)\n",
    "    \n",
    "# Una vez que tenemos todos los trains y tests, sacamos el MSE y R^2 en base a el promedio de estos\n",
    "SumaMSE = 0\n",
    "SumaR2 = 0\n",
    "for i in range(5):\n",
    "    xtrain = X.iloc[trains[i]]\n",
    "    xtest = X.iloc[tests[i]]\n",
    "    ytrain = Y.iloc[trains[i]]\n",
    "    ytest = Y.iloc[tests[i]]\n",
    "\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(xtrain, ytrain)\n",
    "    galton_pred = regr.predict(xtest)\n",
    "    \n",
    "    SumaMSE += mean_squared_error(ytest, galton_pred)\n",
    "    SumaR2 += r2_score(ytest, galton_pred)\n",
    "\n",
    "SumaMSE = SumaMSE/5\n",
    "SumaR2 = SumaR2/5\n",
    "\n",
    "print('Mean squared error model 1: %f'\n",
    "      % SumaMSE)\n",
    "print('Coeficiente r2 model 1: %.2f'\n",
    "      % SumaR2)\n",
    "\n",
    "#####################################################################\n",
    "# Aplicamos en los otros dos modelos anteriores:\n",
    "\n",
    "X = galton[['father','mother','male','female']]\n",
    "Y = galton['height']\n",
    "KF = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "trains = []\n",
    "tests = []\n",
    "for train_index, test_index in KF.split(X):\n",
    "    trains.append(train_index)\n",
    "    tests.append(test_index)\n",
    "    \n",
    "# Una vez que tenemos todos los trains y tests, sacamos el MSE y R^2 en base a el promedio de estos\n",
    "SumaMSE = 0\n",
    "SumaR2 = 0\n",
    "for i in range(5):\n",
    "    xtrain = X.iloc[trains[i]]\n",
    "    xtest = X.iloc[tests[i]]\n",
    "    ytrain = Y.iloc[trains[i]]\n",
    "    ytest = Y.iloc[tests[i]]\n",
    "\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(xtrain, ytrain)\n",
    "    galton_pred = regr.predict(xtest)\n",
    "    \n",
    "    SumaMSE += mean_squared_error(ytest, galton_pred)\n",
    "    SumaR2 += r2_score(ytest, galton_pred)\n",
    "\n",
    "SumaMSE = SumaMSE/5\n",
    "SumaR2 = SumaR2/5\n",
    "\n",
    "print('Mean squared error model 2: %f'\n",
    "      % SumaMSE)\n",
    "print('Coeficiente r2 model 2: %.2f'\n",
    "      % SumaR2)\n",
    "\n",
    "# Model 3\n",
    "\n",
    "X = galton[['mother','male','female']]\n",
    "Y = galton['height']\n",
    "KF = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "trains = []\n",
    "tests = []\n",
    "for train_index, test_index in KF.split(X):\n",
    "    trains.append(train_index)\n",
    "    tests.append(test_index)\n",
    "    \n",
    "# Una vez que tenemos todos los trains y tests, sacamos el MSE y R^2 en base a el promedio de estos\n",
    "SumaMSE = 0\n",
    "SumaR2 = 0\n",
    "for i in range(5):\n",
    "    xtrain = X.iloc[trains[i]]\n",
    "    xtest = X.iloc[tests[i]]\n",
    "    ytrain = Y.iloc[trains[i]]\n",
    "    ytest = Y.iloc[tests[i]]\n",
    "\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(xtrain, ytrain)\n",
    "    galton_pred = regr.predict(xtest)\n",
    "    \n",
    "    SumaMSE += mean_squared_error(ytest, galton_pred)\n",
    "    SumaR2 += r2_score(ytest, galton_pred)\n",
    "\n",
    "SumaMSE = SumaMSE/5\n",
    "SumaR2 = SumaR2/5\n",
    "\n",
    "print('Mean squared error model 3: %f'\n",
    "      % SumaMSE)\n",
    "print('Coeficiente r2 model 3: %.2f'\n",
    "      % SumaR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-photograph",
   "metadata": {},
   "source": [
    "### Qué k es mejor usar? \n",
    "\n",
    "Usualmente se trabaja con k = 5 o k = 10, aunque algunas veces tiene sentido hacer que k se el tamaño del dataset (eso se conoce como \"leave one out cross validation\"). Ante la duda, ¡probar con k = 5 y k = 10! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-hearing",
   "metadata": {},
   "source": [
    "### Alternativa 3: Regularizar con LASSO. \n",
    "\n",
    "Otra alternativa para reducir el overfitting es poner una penalización en la función de verosimilitud a la hora de maximizarla. Es decir, vamos a maximizarla, pero vamos a incluir una penalización que depende de la cantidad coeficientes. Esto va a *empujar* a que algunos de esos coeficientes sean 0, cuando la diferencia entre la verosimilitud con/sin esos coeficientes es pequeña. \n",
    "\n",
    "Nosotros solo vamos a ver LASSO, que corresponde a penalizar con el valor absoluto de cada coeficiente: para una regresión sobre entidades con $n$ atributos, la verosimilitud penalizada $\\mathcal P(\\bar x \\mid p)$ se calcula como \n",
    "$$\\mathcal P(\\bar x \\mid p) = \\mathcal L(\\bar x \\mid p) - \\lambda\\sum_{1 \\leq i \\leq n}|\\beta_i|.$$\n",
    "\n",
    "Acá, $\\lambda$ es un parámetro que debe ser proveído por el cientista de datos a cargo de entrenar el modelo (aunque podemos buscar el mejor $\\lambda$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-character",
   "metadata": {},
   "source": [
    "Una cosa importante: Como LASSO suma los coeficientes, es importante **estandarizar** nuestros datos. Para eso, tomamos vada valor v y lo transformamos en $(v-\\text{media})/ (\\text{desviacion estandar})$. Nauralmente, no hacemos esto con las variables indicatrices (*male*, *female*) por que esos datos ya vienen estandarizados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "banner-spencer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>father</th>\n",
       "      <th>mother</th>\n",
       "      <th>kids</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.751494</td>\n",
       "      <td>1.263788</td>\n",
       "      <td>-0.795431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.797225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.751494</td>\n",
       "      <td>1.263788</td>\n",
       "      <td>-0.795431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.680816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.751494</td>\n",
       "      <td>1.263788</td>\n",
       "      <td>-0.795431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.624996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.751494</td>\n",
       "      <td>1.263788</td>\n",
       "      <td>-0.795431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.624996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.537045</td>\n",
       "      <td>1.047058</td>\n",
       "      <td>-0.795431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.880955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     father    mother      kids  male  female    height\n",
       "0  3.751494  1.263788 -0.795431   1.0     0.0  1.797225\n",
       "1  3.751494  1.263788 -0.795431   0.0     1.0  0.680816\n",
       "2  3.751494  1.263788 -0.795431   0.0     1.0  0.624996\n",
       "3  3.751494  1.263788 -0.795431   0.0     1.0  0.624996\n",
       "4  2.537045  1.047058 -0.795431   1.0     0.0  1.880955"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "galton_std = galton[['father','mother','kids','male','female','height']].copy()\n",
    "for column in galton_std.columns:\n",
    "   if column != 'male' and column != 'female':\n",
    "        galton_std[column] = (galton_std[column] - galton_std[column].mean()) / galton_std[column].std()\n",
    "\n",
    "galton_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-fight",
   "metadata": {},
   "source": [
    "Recuerda que el significado de estos números en versión estandarizada indica cuantas desviaciones estándar están desde la media (positivo es más a la derecha de la media, negativo es a la izquierda). \n",
    "\n",
    "Entrenemos ahora una regresión con LASSO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "killing-orchestra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.30736471e-01  1.56898288e-01 -0.00000000e+00  1.25207987e+00\n",
      " -5.38734282e-16]\n",
      "-0.6483487067255513\n",
      "Mean squared error: 0.375212\n",
      "Coeficiente r2: 0.62\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos una regresión con lasso, usamos un alfa de 0.05\n",
    "regr_regularizado = linear_model.Lasso(alpha=0.05)\n",
    "\n",
    "regr_regularizado.fit(galton_std[['father','mother','kids','male','female']], galton_std['height'])\n",
    "\n",
    "print(regr_regularizado.coef_)\n",
    "print(regr_regularizado.intercept_)\n",
    "\n",
    "regr_regularizado.predict(para_predecir)\n",
    "\n",
    "#Ahora predecimos un poco y calculamos el MSE y r^2\n",
    "galton_pred = regr_regularizado.predict(galton_std[['father','mother','kids','male','female']])\n",
    "\n",
    "#y calculamos \n",
    "print('Mean squared error: %f'\n",
    "      % mean_squared_error( galton_std['height'], galton_pred))\n",
    "\n",
    "print('Coeficiente r2: %.2f'\n",
    "      % r2_score(galton_std['height'], galton_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-barrel",
   "metadata": {},
   "source": [
    "Fijate como ha desaparecido el coeficiente correspondiente a *kids*, y como casi desaparece el de *female* (este es superfluo, basta con uno entre male/female. Es por este motivo que LASSO tiende a regularizar de forma práctica: los valores de los coeficientes van bajando hasta transformarse en 0. \n",
    "\n",
    "Lo otro que es interesante: fíjate como ha subido el coeficiente r^2. El MSE no es comparable con el de la regresión que no está estandarizada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-candidate",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "Busca el mejor $\\lambda$ para usar LASSO. PAra ver cuál modelo es mejor, usa 5-fold cross validation, y selecciona los modelos que tengan el menor MSE (o el menor r^2, como prefieras). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "infectious-scoop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error con lambda = 0.05: 0.375212\n",
      "Coeficiente r2 con lambda = 0.05: 0.62\n",
      "Mean squared error con lambda = 0.1: 0.421078\n",
      "Coeficiente r2 con lambda = 0.1: 0.58\n",
      "Mean squared error con lambda = 0.03: 0.364828\n",
      "Coeficiente r2 con lambda = 0.03: 0.63\n",
      "Mean squared error con lambda = 0.01: 0.359540\n",
      "Coeficiente r2 con lambda = 0.01: 0.64\n",
      "Mean squared error con lambda = 0.005: 0.359044\n",
      "Coeficiente r2 con lambda = 0.005: 0.64\n",
      "Mean squared error con lambda = 5e-05: 0.358879\n",
      "Coeficiente r2 con lambda = 5e-05: 0.64\n",
      "\n",
      "El valor del nuestras validaciones decienden a medida cada baja el valor de nuetro lamda. El valor optimo debe de ser un valor inferior a 0.00005, pero ya la variación es minima desde entonces.\n"
     ]
    }
   ],
   "source": [
    "# Para buscar el menor lamda evaluare casos en busqueda de un patron.\n",
    "\n",
    "class LassoModel:\n",
    "  def __init__(self, params, target, lamda):\n",
    "    self.params = params\n",
    "    self.target = target\n",
    "    self.lamda = lamda\n",
    "\n",
    "  def CalculateParams(self):\n",
    "    regr = linear_model.Lasso(alpha=self.lamda)\n",
    "    regr.fit(self.params, self.target)\n",
    "\n",
    "    #Ahora predecimos un poco y calculamos el MSE y r^2\n",
    "    galton_pred = regr.predict(self.params)\n",
    "\n",
    "    #y calculamos \n",
    "    print(f'Mean squared error con lambda = {self.lamda}: %f'\n",
    "          % mean_squared_error( self.target, galton_pred))\n",
    "\n",
    "    print(f'Coeficiente r2 con lambda = {self.lamda}: %.2f'\n",
    "          % r2_score(self.target, galton_pred))\n",
    "\n",
    "# Lamda = 0.05\n",
    "model1 = LassoModel(galton_std[['father','mother','kids','male','female']], galton_std['height'], 0.05)\n",
    "model1.CalculateParams()\n",
    "\n",
    "# Lamda = 0.1\n",
    "model2 = LassoModel(galton_std[['father','mother','kids','male','female']], galton_std['height'], 0.1)\n",
    "model2.CalculateParams()\n",
    "\n",
    "# Lamda = 0.03\n",
    "model3 = LassoModel(galton_std[['father','mother','kids','male','female']], galton_std['height'], 0.03)\n",
    "model3.CalculateParams()\n",
    "\n",
    "# Lamda = 0.01\n",
    "model4 = LassoModel(galton_std[['father','mother','kids','male','female']], galton_std['height'], 0.01)\n",
    "model4.CalculateParams()\n",
    "\n",
    "# Lamda = 0.005\n",
    "model5 = LassoModel(galton_std[['father','mother','kids','male','female']], galton_std['height'], 0.005)\n",
    "model5.CalculateParams()\n",
    "\n",
    "# Lamda = 0.00005\n",
    "model6= LassoModel(galton_std[['father','mother','kids','male','female']], galton_std['height'], 0.00005)\n",
    "model6.CalculateParams()\n",
    "\n",
    "print(\"\\nEl valor del nuestras validaciones decienden a medida cada baja el valor de nuetro lamda. El valor optimo debe de ser un valor inferior a 0.00005, pero ya la variación es minima desde entonces.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-tournament",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "soviet-spirit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1:\n",
      "Mean squared error: 0.383641\n",
      "Coeficiente r2: 0.61\n",
      "Model 2:\n",
      "Mean squared error: 0.451536\n",
      "Coeficiente r2: 0.55\n",
      "Model 3:\n",
      "Mean squared error: 0.438997\n",
      "Coeficiente r2: 0.56\n",
      "\n",
      "A partir de los resultados, nuestro caso con menor porcentaje de error corresponderia al caso donde se considera al padre, madre e hijos en el caso.\n"
     ]
    }
   ],
   "source": [
    "X = galton[['father','mother','kids','male','female']]\n",
    "Y = galton['height']\n",
    "\n",
    "class LassoFoldModel:\n",
    "  def __init__(self, X, Y, lamda):\n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "    self.lamda = lamda\n",
    "\n",
    "  def CalculateParams(self):\n",
    "    KF = KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "    trains = []\n",
    "    tests = []\n",
    "    for train_index, test_index in KF.split(self.X):\n",
    "        trains.append(train_index)\n",
    "        tests.append(test_index)\n",
    "\n",
    "    # Una vez que tenemos todos los trains y tests, sacamos el MSE y R^2 en base a el promedio de estos\n",
    "    SumaMSE = 0\n",
    "    SumaR2 = 0\n",
    "    for i in range(5):\n",
    "        xtrain = self.X.iloc[trains[i]]\n",
    "        xtest = self.X.iloc[tests[i]]\n",
    "        ytrain = self.Y.iloc[trains[i]]\n",
    "        ytest = self.Y.iloc[tests[i]]\n",
    "\n",
    "\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(xtrain, ytrain)\n",
    "        galton_pred = regr.predict(xtest)\n",
    "\n",
    "        SumaMSE += mean_squared_error(ytest, galton_pred)\n",
    "        SumaR2 += r2_score(ytest, galton_pred)\n",
    "\n",
    "    SumaMSE = SumaMSE/5\n",
    "    SumaR2 = SumaR2/5\n",
    "\n",
    "    print('Mean squared error: %f'\n",
    "          % SumaMSE)\n",
    "    print('Coeficiente r2: %.2f'\n",
    "          % SumaR2)\n",
    "\n",
    "print(\"Model 1:\")\n",
    "model1 = LassoFoldModel(galton_std[['father','mother','kids','male','female']], galton_std['height'], 0.00005)\n",
    "model1.CalculateParams()\n",
    "\n",
    "print(\"Model 2:\")\n",
    "model2 = LassoFoldModel(galton_std[['mother','kids','male','female']], galton_std['height'], 0.00005)\n",
    "model2.CalculateParams()\n",
    "\n",
    "print(\"Model 3:\")\n",
    "model3 = LassoFoldModel(galton_std[['mother','male','female']], galton_std['height'], 0.00005)\n",
    "model3.CalculateParams()\n",
    "\n",
    "\n",
    "print(\"\\nA partir de los resultados, nuestro caso con menor porcentaje de error corresponderia al caso donde se considera al padre, madre e hijos en el caso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
